## 2023MathorCup数学建模论文

## 电商零售商家需求预测及库存优化问题研究

### 摘要

线上购物是近些年来兴起的新购物浪潮之一，电商平台及其零售商家作为线上购物的主要支持方，面对不同的市场浪潮，基于历史数据通过算法得到历史一般规律，对下一阶段的需求量进行预测，进而支持库存优化等后续相关问题的决策，是一项具有重要应用意义的工作。

针对问题一，我们对数据整理得到了1996个**时间序列**，并通过**回归随机森林模型**对时间序列进行了均值回归，并引入均方差（MSE）和Durbin-Watson（DW）检验来衡量模型的预测准确率。另外，我们建立了**历史波动随机变量模型**来衡量时间序列的波动规律，作为**库存优化**等后续决策的另一方面支持。对于问题一的分类问题，我们引入**动态时间规整模型**（DTW）来衡量时间序列的相似程度，在DTW的基础上设计了**基于DTW的改进K均值聚类模型**，并根据附件2-4中的语义标签建立了**相似度检验模型**，用来衡量聚类分析的聚类效果，并指导聚类模型的超参数调整，最终得到分为15类的时间序列聚类簇，其同一类别在需求上的特征最为相似。

针对问题二，我们采取**残缺时间序列补全模型**和**迁移学习模型**相结合的方法，对附件5的时间序列进行了均值回归。我们在问题一的基础上采用DTW模型和相似度检验模型，以新维度的时间序列为聚类中心，依次对问题一中的时间序列进行**归类**。采用归类的时间序列对残缺时间序列进行补全，并采用问题一中已经经过大量训练、结构优化和参数迭代的回归随机森林模型，对**补全时间序列**进行均值回归，得到预测结果。

针对问题三，我们考虑到出货量的**时间序列波动趋势**也类似于一种信号，在较大范围内拥有周期性变化的特征，其峰值的到达常常与外界因素有关，如“大型促销”等。我们借鉴**太阳黑子**周期性变化规律中的研究方法，引入**电商波动相对指数**，并对**现实情况**进行了相关调查，建立了**叠加电商波动相对指数的均值回归模型**，采用该模型对附件6的时间序列维度进行回归分析，得到包含**波动趋势**的预测结果，以支持大型促销等特殊市场浪潮的优化决策。

关键词：时间序列，回归随机森林，相似度检验模型，迁移学习，电商波动相对指数

### 问题重述

#### 背景

电商平台存在着上千个商家，他们会将商品货物放在电商配套的仓库，电商平台会对这些货物进行统一管理。大数据智能驱动的供应链研究可以通过分析历史一段时间每种“商家”、“仓库”、“商品”维度的出货量数据，预测未来一段时间的时间序列的走势，显著降低库存成本，同时保证商品的按时履约。同时，企业会根据数据的历史情况，分析出需求量序列的数理特征，对相似的需求量序列进行归类，并根据归类结果做到更加精准的预测。然而，在实际的电商供应链预测任务中，常常会出现多种复杂情境。如部分商品销售时间过短、仓库存在新增或切换等情况，导致该预测维度下历史数据过少；另外，部分大型促销期间货量的陡增并由此带来的不规律性，也给需求量的精准预测带来了不小的难度。此时便需要通过算法得到历史一般规律，找出相似的历史情况，从而实现精准预测。

#### 问题提出

请你们参赛队伍按照题目中所给的需求预测和库存优化等电商供应链场景，结合附件1至6的数据，完成以下问题：

**问题一：**使用附件1-4中的数据，预测出各商家在个仓库的商品2023-05-16至2023-05-30的需求量，请将预测结果填写在结果表1，并对你们模型的预测性能进行评价。另外请讨论：根据数据分析及建模过程，这些由商家、仓库、商品形成的时间序列如何分类，时同一类别在需求上的特征最为相似？

**问题二：**现有一些新出现的商家+仓库+商品维度，导致这种情况出现的原因可能是新上市的商品，或是改变了某些商品所存放的仓库。请讨论这些新出现的预测维度如何通过历史附件1中的数据进行参考，找到相似序列并完成这些维度在2023-05-16至2023-05-30的预测值。请把预测结果填写在结果表2。

**问题三：**每年6月会出现规律性的大型促销，为需求量的精准预测以及履约带来了很大的挑战。附件6给出了附件1对应的商家+仓库+商品维度在去年双十一期间的需求量数据，请参考这些数据，给出2023-06-01至2023-06-20的预测值，并将预测结果填写在结果表3。

### 问题分析

#### 数据预处理

本题附件1给出的数据共331336行，附件5给出的数据共7429行，附件6给出的数据共21355行，数据量较为庞大且排列顺序并不按时间戳进行，为使后续工作顺序进行，我们编写python程序对附件数据进行了预处理，进行了数据清洗，排除了重复和异常项，按照时间戳对数据进行重新排列，并将商家、商品和仓库的字符串名称进行处理，便于后续的数据提取和转化工作。

#### **问题一分析**

本题目在于在庞大的数据量中提取每个维度的全部时间序列，并针对电商平台出货量这种特殊类型的时间序列寻找一种性能较好的回归模型，对此我们采取回归随机森林进行均值回归，同时建立历史波动随机变量，用于体现时间序列的波动规律。此外，题目要求根据数据分析和建模的过程，对时间序列数据集进行分类，使其在需求上的特征最为相似，对此我们采取基于DTW距离的改进K均值聚类分析，对1996个时间序列进行聚类，并根据附件2-4建立相似度检验模型，对聚类结果进行进一步检验。

#### **问题二分析**

本题目在于有一些新出现的商家+仓库+商品维度，其时间序列长度较短，无法支撑回归分析。我们考虑通过附件1的数据进行参考，基于第一问的DTW模型和相似度检验模型，以新维度的时间序列为聚类簇中心，对附件1的时间序列进行归类，并用归类结果补全新维度的时间序列。最后，我们采取迁移学习，利用问题一中以及训练成熟的回归随机森林对问题二的补全时间序列进行回归分析。

#### **问题三分析**

本题目考虑每年6月出现的规律性的大型促销会给商品需求量带来较大波动，希望参考去年双十一期间的需求量数据对2023年6月份的20天的需求量进行预测。我们考虑到出货量的时间序列波动趋势类似于一种信号，在较大范围内拥有周期性变化的特征，其峰值的到达常常与外界因素有关，如“大型促销”等。所以我们参考通过太阳黑子研究太阳周期性活动的研究过程，对规律性的大型促销时间段引入电商波动相对指数，进行叠加电商波动相对指数的均值回归。同时，我们结合对现实情况的调查，对6月18日前后的需求量数据进行特殊处理，使其更符合现实需求。

### 模型假设

为了便于考虑问题，我们在不影响准确性的前提下，做出以下假设：

（1）假设时间序列维度的商家、商品和仓库的语义标签在我们指定的维度上具有较明显的区别特征。

（2）假设新维度时间序列可以通过语义标签进行相似度检验。

（3）假设回归分析的过程中无其它异常情况影响。

（4）假设大型促销的时间范围较大，从6月初就已经开始。

### 符号表

![QQ图片20231031133042](https://gitee.com/guyue12346/cloud-image-library/raw/master/QQ图片20231031133042.jpg)

### 问题一模型的建立和求解

#### 预测策略的确定

在本次整个数学建模问题中，我们考虑到主要任务是针对库存方和平台方的出货量进行预测，其根本目的是通过预测为库存优化和后续一系列决策提供支持，单个时间序列在仅有历史出货量数据支持的前提下，精确到每一天的准确预测在理论上的可行性空间较小，在决策支持上给予的数据支撑单薄。我们认为，时间序列的预测应当从两个方面考虑，一是每种时间序列过滤大幅度波动后的均值回归，这反映了商品在无较大外部因素扰动下的平均需求量，这是考虑库存优化时的决策基准；二是每种时间序列的波动规律，包括波动幅度，波动周期等，这反映了商品受外界多方面因素影响时偏离回归均值的归类，以便决策者在面对市场规律浪潮时为库存优化等一系列决策做出更加充分的准备，同时预留出适当的缓冲空间和周转余地。综合上述两种要素，决策者可以在多方面因素的影响下做出更优的决策。而我们后续三个问题的建模与求解，均基于上述思想进行，在填写预测结果表时，我们考虑到不同情境下的决策重点，从而给出更有助于优化决策的预测值数据集。

![未命名文件(16)](https://gitee.com/guyue12346/cloud-image-library/raw/master/未命名文件(16).png)

#### 时间序列的确定

对于给出的数据集附件1-商家历史出货量表，我们编写python程序对其进行了数据清洗，排除其重复数据和异常数据，然后筛选出所有的商品+商家+仓库维度，并将其对应的出货量按照时间戳进行排序，得到了1996个时间序列,每个时间序列长166天，其第H个组合维度对应的时间序列T为：

$$
\left[x_i, y_{\bar{i}}, z_i\right]^H:\left[q_1, q_2, q_3 \cdots q_{n-1}, q_n\right]^T
$$

#### 随机森林

随机森林属于集成学习算法的一种，其核心思想是集成多个弱分类器，从而实现一个预测效果更好的集成分类器。随机森林可以同时胜任回归和分类两大任务。

随机森林基于决策树构建而成，主要思想是通过组合多个决策树来提高模型的性能和稳定性。

随机森林的关键特点和工作原理：

1. 随机选择特征：在构建每棵决策树的过程中，随机选择一部分特征进行训练，而不是使用所有的特征。这有助于减少过拟合的风险，并增加模型的多样性。
2. 随机采样数据：对于每棵树的训练数据，随机抽取部分样本进行训练，这被称为自助采样（bootstrap sampling）。这意味着某些样本可能在多棵树的训练中被重复采样，而某些样本可能从未被选中。
3. 多树组合：随机森林通常包含多棵决策树，这些树独立构建，并且没有共享信息。在分类问题中，每棵树投票决定最终的类别；在回归问题中，每棵树的预测结果取平均值。
4. 随机性和多样性：随机森林的随机性来自于特征选择和数据采样，这有助于防止过拟合。多棵树的组合提供了模型的稳定性和鲁棒性，使其适用于各种问题。

其基本结构示意图如图：

![df8903b5b7385ee40b8499566f870cf3](https://gitee.com/guyue12346/cloud-image-library/raw/master/df8903b5b7385ee40b8499566f870cf3.png)

随机森林算法在处理大规模时间序列的优点在于：

1. 在建造森林时，可以在内部对于一般化后的误差产生不偏差的估计
2. 可以有效处理大量的输入变量
3. 对于不平衡的时间序列资料集来说，可以平衡误差
4. 包含一个好方法可以估计丢失的资料，并且如果有很大一部分的资料丢失，仍可以维持准确度
5. 可被延伸应用在未经标记的时间序列上
6. 学习过程迅速

综合上述考量，我们选取随机森林进行进行多维度的时间序列均值回归，并削弱其波动规律的影响，得到一般意义上的回归均值。

#### 回归随机森林

基于随机森林的设计思想，我们设计出基于时间序列的回归随机森林。在回归随机森林中，多个决策树组合起来进行预测，最终输出是这些树的预测结果的平均值。与单一决策树相比，回归随机森林通常能够提供更稳健的预测，减少过拟合的可能性，并对数据中的噪声更具鲁棒性。

其过程示意图如图：

![未命名文件(17)](https://gitee.com/guyue12346/cloud-image-library/raw/master/未命名文件(17).png)

#### 预测准确率检验

对于验证集数据的检验方法，我们认为加权平均绝对百分比误差（wmape）在这种模型中的参考价值已不大，因为我们过滤时间序列中的波动规律，求得一般性的均值回归的过程中，峰值处的较大误差会使整个wmape在数值上失真。所以，我们考虑均方误差（MSE）和Durbin-Watson（DW）检验相结合的方法构建预测准确率检验模型：（此处可改为大括号）

$$
\begin{aligned}
\text {      MSE   }=\frac{\sum\left(  y_i-\hat{y}_i\right)^2}{n}\& 
 D W  & =\frac{\sum_{t=2}^n\left(\varepsilon_t-\varepsilon_{t-1}\right)^2}{\sum_{t=1}^n \varepsilon_t^2}
\end{aligned}
$$

其中MSE用来检验回归数据集在整个数据集上的偏差程度和波动程度，DW则用于检测线性回归模型中的残差（误差项）是否存在自相关性。

其中一次均值回归的MSE如图：（DW再补充）

![均方误差图](https://gitee.com/guyue12346/cloud-image-library/raw/master/均方误差图.png)

发现部分时间序列的MSE在较大程度上偏离数据集的MSE范围，我们考虑这种数据集在训练集上的基础数值过大，对其进行单独处理后重新进行回归。

对其中一个时间序列进行DW检验如图：

![图90](https://gitee.com/guyue12346/cloud-image-library/raw/master/图90.png)

![图91](https://gitee.com/guyue12346/cloud-image-library/raw/master/图91.png)

基于MSE和DW的预测准确率检验反馈，我们不断调整和优化回归随机森林模型结构及相关超参数，同时过滤了数据集中的较大波动，获得了训练出针对电商平台需求量时间序列的回归随机森林模型。

#### 回归预测

在经过波动过滤和超参数优化后，我们训练出针对电商平台需求量时间序列的回归森林模型，对1996个时间序列进行了均值回归，根据回归的结果进行各商家在各仓库的商品在2023-05-16至2023-05-30的需求量预测，并同时绘制了每个时间序列的回归与预测效果图。

以商家5-商品43-仓库1为例，其回归与预测效果图如图：

![5_43_1](https://gitee.com/guyue12346/cloud-image-library/raw/master/5_43_1.png)

从图中可以看出，在整个训练集上，随机森林使用滑动窗口进行特征提取时，部分忽略了其波动较大的峰值，这一特征在验证集的回归图中体现更加明显：回归曲线在平稳范围内进行波动，并选择性地忽略了极大波动的峰值。在预测效果图中，我们可以看出2023-05-16至2023-05-30的需求量预测都在一个稳定的范围内进行波动，提供了一个较为稳健的均值回归，反映了时间序列的波动回归点。

在问题一中，我们将此次回归预测的结果作为本题结果写入附件表格，因为我们认为，在较长时间跨度上进行回归分析，其得到的回归均值更有助于决策者对长期库存规划等决策进行更稳健地处理，以应对长期战略发展地需要。但也要注意到，我们在问题一后续的建模中会进行对时间序列波动规律的建模，不同商品的时间序列波动规律也应当是决策者进行决策时需要参考的维度。

#### 历史波动随机变量

对于时间序列预测所需的波动情况也需要从已有的时间序列数据得到。我们认为，这种波动来源于市场的随机行为，可以用随机变量的统计分析进行描述。本问题中，定义逐差时间序列:

![img](../AppData/Local/Temp/ksohtml25568/wps1.jpg)

对![img](https://gitee.com/guyue12346/cloud-image-library/raw/master/wps2.jpg)作统计分析，可以得到逐差D的统计分布，预测中按照此统计分布抽样得到每天的逐差![img](../AppData/Local/Temp/ksohtml25568/wps3.jpg)，叠加在随机森林预测得到的![img](../AppData/Local/Temp/ksohtml25568/wps4.jpg)上作为波动修正，模拟出反映实际时间序列特征的变化趋势:

![img](../AppData/Local/Temp/ksohtml25568/wps5.jpg)

作为库存规划的参考。计算中，我们限制以下条件：

![img](../AppData/Local/Temp/ksohtml25568/wps6.jpg)

![img](../AppData/Local/Temp/ksohtml25568/wps7.jpg)

第一式代表如果时间序列按照此波动进行，不会出现预测值为负的情形，第二式则使波动修正的![img](../AppData/Local/Temp/ksohtml25568/wps8.jpg)恒正。式中![img](../AppData/Local/Temp/ksohtml25568/wps9.jpg)为预测的第一天，![img](../AppData/Local/Temp/ksohtml25568/wps10.jpg)为已有时间序列的最后一天，![img](https://gitee.com/guyue12346/cloud-image-library/raw/master/wps11.jpg)为预测序列的最后一天。可以发现，![img](../AppData/Local/Temp/ksohtml25568/wps12.jpg)之和为![img](../AppData/Local/Temp/ksohtml25568/wps13.jpg)尾首数值之差，即:

![img](../AppData/Local/Temp/ksohtml25568/wps14.jpg)

这个差值分散在整个序列上，再加上限制条件的影响，![img](https://gitee.com/guyue12346/cloud-image-library/raw/master/wps15.jpg)整体上呈现正负均匀的特征，很好地代表了波动性而不包含多余信息。

#### 时间序列的分类

##### 聚类分析

聚类分析（Cluster Analysis）是一种无监督学习方法，旨在将数据集中的对象划分成不同的组（或簇），以使同一组内的对象彼此相似，而不同组之间的对象彼此不同。聚类是一种探索性数据分析技术，用于发现数据中的隐藏结构，而不需要预先知道数据的标签或类别。

聚类分析中的一些关键概念和方法：

1. **簇**：簇是一组相似的数据点，它们在某种度量空间中彼此接近，但与其他簇的数据点不太接近。簇内的数据点应该具有高度相似性，而簇间的数据点应该具有较低的相似性。
2. **相似性度量**：聚类分析通常使用某种相似性或距离度量来衡量数据点之间的相似性或距离。常用的度量包括欧氏距离、曼哈顿距离、余弦相似度等。
3. **聚类算法**：有许多不同的聚类算法，每个算法都有其独特的方法来确定簇。一些常见的聚类算法包括：
   - K-Means：一种迭代聚类算法，通过最小化簇内数据点与其质心的平方距离来分配数据点到簇。
   - 层次聚类：根据数据点之间的相似性逐渐构建层次结构的簇。
   - DBSCAN：一种基于密度的聚类算法，将数据点聚类成具有不同密度的簇。
   - 高斯混合模型（GMM）：一种使用概率分布来建模数据点分布的聚类方法。
   - 谱聚类：使用数据点之间的相似性矩阵来进行聚类。
4. **簇数目**：确定要分成多少个簇通常是聚类分析的一个关键问题。某些算法（如K-Means）需要提前指定簇的数量，而其他算法（如DBSCAN）可以自动确定。
5. **评估**：对聚类质量的评估通常需要使用一些指标，如轮廓系数、Davies-Bouldin指数等。这些指标可以帮助确定哪种聚类解决方案更好。

##### 基于DTW的改进K均值聚类分析

在现实情况中，企业会首先根据数据的历史情况，分析出需求量序列的数理特征，对相似的需求量序列进行归类，根据分类结果我们可以进行更加精确的预测。考虑到处理的数据集是时间序列这样一种特殊的数据集，我们采用动态时间规整（DTW）方法来分析时间序列之间的相似数理特征。DTW可以在时间序列中找到相似的子序列，从而实现特征匹配；并且DTW对噪声和异常值的鲁棒性相对较强，可以较好的排除异常情况的影响。对1996个时间序列之间进行DTW距离计算，并将计算结果保存在矩阵中，得到大小为1996*1996的Distance_Matrix（D-M）矩阵：

$$
D-M：\left[\begin{array}{llll}
d_{11}··· & & & \\
& ···d_{i, j}··· & & \\
& & & \\
& & ···d_{1996,1996}
\end{array}\right]
$$

其中

$$
d_{i,j}:第i和时间序列和第j个时间序列的DTW距离
$$

基于DTW矩阵来衡量时间序列之间的相似数理特征，我们对传统的K均值聚类分析进行优化和改进，使用DTW距离代替欧氏距离，并对一些模块进行了结构优化，使其在对时间序列数据集的聚类分析上拥有更好的针对性和精确性。从而得到了基于DTW距离的K均值聚类分析模型，其中i为聚类中心的个数：

$$
DTW-K-i:\left[Q_{i}^k \cdots Q_{j}^k\right]
$$

#### 分类相似度检验

##### 语义标签的数学化

![QQ图片20231101135650](https://gitee.com/guyue12346/cloud-image-library/raw/master/QQ图片20231101135650.jpg)

##### 基于语义标签的相似度算法

##### 矩阵元计算

考虑到基于DTW距离的K均值聚类分析只关注时间序列数据集的出货量关于时间的数理特征，而未考虑到商品+商家+仓库维度上的特征，我们考虑基于附件2-商品信息表、附件3-商家信息表、附件4-仓库信息表，建立聚类簇的相似度检验模型。我们对附件中的商品、商家、仓库分别赋予对应的相似度衡量标签：

$$
\begin{aligned}
& {[category]:[ 购买周期、 受众范围、平均价格、价格波动、存储周期 ]^*} \\
& [\text { seller }]:[商家类型、 规模[大、中、小]]^* \\
& {[\text { warehouse}]:[经济水平[高、中、低]]^*}
\end{aligned}
$$

其中category的相似度标签数据如下：

| category      | 平均价格 | 购买周年 | 受众人群 | 价格波动 | 存储周年 |
| ------------- | -------- | -------- | -------- | -------- | -------- |
| 家装建材      | 400      | 10       | 0.3      | 200      | 3        |
| 酒类          | 200      | 1        | 0.2      | 200      | 5        |
| 家用电器      | 2000     | 8        | 0.3      | 500      | 4        |
| 食品饮料      | 5        | 0.01     | 1        | 30       | 0.5      |
| 宠物生活      | 50       | 0.1      | 0.3      | 20       | 0.8      |
| 手机通讯      | 1000     | 3        | 0.8      | 50       | 0.8      |
| 电脑、办公    | 3000     | 5        | 0.5      | 300      | 1        |
| 厨具          | 20       | 1        | 0.3      | 5        | 0.7      |
| 美妆护肤      | 100      | 0.8      | 0.5      | 30       | 0.6      |
| 玩具乐器      | 50       | 2        | 0.2      | 20       | 1        |
| 个人护理      | 40       | 0.4      | 0.9      | 10       | 0.5      |
| 服饰内衣      | 60       | 0.5      | 1        | 20       | 0.9      |
| 家庭清洁/纸品 | 35       | 0.2      | 0.5      | 10       | 0.6      |
| 鲜花/奢侈品   | 200      | 1.5      | 0.2      | 30       | 0.3      |
| 数码          | 1000     | 3        | 0.5      | 50       | 1.2      |
| 生活日用      | 40       | 0.3      | 0.9      | 10       | 0.4      |
| 运动户外      | 100      | 1.5      | 0.6      | 20       | 0.8      |
| 家具          | 500      | 8        | 0.3      | 300      | 4        |
| 珠宝首饰      | 300      | 2        | 0.2      | 50       | 2        |
| 传统滋补      | 200      | 0.8      | 0.3      | 20       | 0.6      |
| 汽车用品      | 100      | 1        | 0.6      | 30       | 1.2      |
| 宠物健康      | 50       | 0.2      | 0.3      | 20       | 1        |
| 箱包皮具      | 60       | 2        | 0.5      | 30       | 0.9      |

利用相关数据集对所有相似度衡量标签进行赋值，并对相似度标签进行归一化处理和加权，我们得到了聚类簇中任意两个时间序列的相似度检验模型S-I，并根据检验结果指导基于DTW距离的K均值聚类分析中聚类中心个数i的再选择和优化，这个过程实现了一个反向传播（BP）优化结构：

$$
S-I
$$

经过迭代调参和数值优化，我们最终得到了基于DTW的K均值聚类的最优聚类数：15。分为15类后的时间序列聚类簇的相似度数值如图：

![相似度](https://gitee.com/guyue12346/cloud-image-library/raw/master/相似度.png)

类内的相似度数值和类间的相似度已有明显差别，类内相似度数值与类间相似度数值之比为：1.423，说明基于DTW的改进K均值聚类分析经过相似度检验的筛选已能达到较好的聚类效果。

#### 时间序列聚类簇的获得

在经过相似度检验和基于DTW距离的K均值聚类分析的超参数调整的BP优化过程之后，我们实现了对1996个时间序列的聚类分析，使同一聚类簇中的时间序列在需求上的特征最为相似，并获得了时间序列聚类簇(Time-Series-Cluster)：

$$
Time-Series-Cluster:\left[\left[x_{\bar{i}}, y_i, z_i\right]^i: Q^i \cdots\right]
$$

### 问题二模型的建立和求解

#### 时间序列的归类

在实际生产过程中，常常会出现一些新的时间序列维度，如新上市的商品，或是改变了某些商品存放的仓库等。此时，往往我们对新的时间序列维度认识不够充分，新维度的时间序列长度也并不支持进行较精确的回归分析，在这种情况下，我们对新维度时间序列在问题一的建模基础上对附件1的时间序列进行归类，并借助归类后的聚类簇内的时间序列数据集为后续的回归分析提供数据上更充分的支持。

时间序列的归类过程我们依次考虑聚类模型和相似度检验模型，其基本过程如图：

![归类图](https://gitee.com/guyue12346/cloud-image-library/raw/master/归类图.png)

##### 考虑聚类模型

我们将每一个新维度的时间序列都视为一个新的聚类簇中心，对于每一个新维度时间序列，我们遍历附件1中的1996个时间序列，找到与其DTW最近的二十个时间序列，以新维度时间序列为聚类簇中心进行归类。这些时间序列与新维度时间序列有着数理特征上的较大相似度。

以第一个新维度Seller No: 19, Product No: 2215, Warehouse No: 21为例，其聚类簇内的20个时间序列与其的DTW距离如图：

![时间序列DTW](时间序列DTW.png)

可以看出选取的时间序列与聚类簇中心的DTW距离都在74~82的小范围内进行波动，说明基于DTW进行归类的数据集在数值上的表现较优。

##### 考虑相似度检验模型

对于聚类中的二十个时间序列，我们考虑从语义标签的相似程度对其进行相似度检验，并从中选取语义标签相似度最高的十个时间序列。（此处加上一个公式，表示时间序列经过相似度检验模型过滤）

由此，我们基于每一个新维度的时间序列对附件1的1996个时间序列进行了归类，新维度的时间序列作为聚类簇中心，聚类簇中的时间序列与簇中心有着数理特征和语义特征两方面的相似，可以为簇中心在进行回归分析时给与数据上的参考和支撑。

#### 回归时间序列数据集

考虑到附件五给出的时间序列作为回归分析的主要数据集，但其整体上时间较短，我们选择残缺时间序列补全和迁移学习的方法相结合。

其中残缺时间序列补全考虑在附件1的时间序列数据集上为附件5中的时间序列数据集进行扩展和补全，以更好的支持随机森林进行均值回归；迁移学习则考虑使用已在同类数据集上进行过大量训练和迭代调参的成熟回归模型直接对补全的时间序列进行均值回归，以提高回归精度和减少重复工程。

其过程如图所示：

![补全回归](https://gitee.com/guyue12346/cloud-image-library/raw/master/补全回归.png)

##### 残缺时间序列补全

 对于每一个新维度的时间序列归类得到的聚类簇，我们取聚类簇中的其它时间序列的平均值作为新维度时间序列在缺失部分的补全，补全得到的新时间序列既拥有了数据长度上的完整性以支持回归分析，又保留了原始数据作为回归分析的重要因素。

以9_2111_1为例：

![9_2111_1](https://gitee.com/guyue12346/cloud-image-library/raw/master/9_2111_1.png)

其时间序列补全部分基本与原时间序列保持数理特征和语义标签上的一致。

##### 迁移学习

迁移学习（Transfer Learning）是一种机器学习方法，它涉及将一个已经训练好的模型（通常是深度神经网络）的知识或特征应用于解决与原始任务不同但相关的新任务。迁移学习的核心思想是，通过从一个任务中学到的知识，可以帮助改善在另一个相关任务上的性能，特别是在新任务的训练数据有限或昂贵的情况下。

考虑新时间序列在数理特征和语义特征两方面都与附件一中的部分时间序列相似，其回归分析的过程也得以借鉴。因此，我们采用迁移学习的方式，使用问题一中已经过架构优化和迭代调参的回归随机森林进行均值回归。

#### 新维度的回归预测

我们根据回归随机森林的训练结果进行了新维度中各商家在各仓库的商品在2023-05-16至2023-05-30的需求量预测，并同时绘制了每个时间序列的回归与预测效果图。

以11_2160_1为例，其回归与预测效果图如图：

可以看出经过补全的新维度时间序列经过回归随机森林的预测数据集在较小范围内进行波动，充分表现出其均值回归的特点。在问题二中我们将此次的回归结果写入结果附件表，我们认为，问题二的回归预测性质同问题一类似，其得到的回归均值更有助于决策者进行稳健的决策，并且新维度的时间序列发展趋势和波动周期尚未定型，因此回归均值更有助于在稳妥的决策基础上，依据于对新维度认识的加深而制定下一步决策，以应对多变的市场需求。

### 问题三模型的建立和求解

#### 太阳黑子

太阳黑子是太阳周期性活动的一个基本标志，是太阳表面可以看到的最突出的现象。它存在于太阳光球表面，是磁场的聚集之处。其数量和位置每隔一段时间会发生周期性变化。

太阳黑子历史变化周期如图：

![v2-268791cdac314cf16fdd468f31894bf6_r](https://gitee.com/guyue12346/cloud-image-library/raw/master/v2-268791cdac314cf16fdd468f31894bf6_r.png)

"太阳黑子相对数"（Solar Sunspot Relative Number）是用来描述太阳黑子活动的指标，通常是每月统计的。这个指标表示每个月观察到的太阳黑子数与历史平均值的比率。太阳黑子相对数通常用来监测太阳活动周期的变化。

其公式如下：

Relative Sunspot Number (RSN)=*K*⋅(10*g*+*f*)/(1+*G*⋅(10*h*+*f*))

其中：

- *K* 是一个尺度因子
- *G* 是另一个尺度因子
- *g* 表示每月的太阳黑子组数。
- *h* 表示每月的太阳黑子的总数。
- *f* 是一个修正因子，通常取值为 1。这个因子用于考虑特殊情况和修正误差。

太阳黑子相对数是一个表示太阳活动水平的指标，它将每月观察到的太阳黑子数量归一化到一个相对值，以便更好地理解太阳活动的变化。

#### 电商出货量周期规律

我们考虑到出货量的时间序列波动趋势也类似于一种信号，在较大范围内拥有周期性变化的特征，其峰值的到达常常与外界因素有关，如“大型促销”等。我们考虑参考太阳黑子周期性变化规律中的研究方法，从去年双十一期间的时间序列数据集和近六月份的日常时间序列数据集提取电商波动相对指数R，以更为精确地预测六月份的需求量峰值。

一些时间序列的折线图如图：

<img src="https://gitee.com/guyue12346/cloud-image-library/raw/master/image-20231101131603019.png" alt="image-20231101131603019" style="zoom:150%;" />

##### 电商波动相对指数

$$
R=k(t* g+f)
$$

其中g为日常波动相对指数，f为促销波动相对指数，t为尺度因子，k为修正因子，R为所求的电商波动相对指数。

###### 日常波动相对指数

###### 促销波动相对指数

##### 现实情况调查

通过我们对现实相关情况的调查，我们发现许多电商平台在6月份伊始就已经开始了相关的活动促销，这是影响需求量的一个重要因素,也符合我们模型的假设。同时，我们发现绝大部分电商平台会在6月18日前后进行大规模的集体促销，故而绝大部分商品的需求量会在这一天前后达到一个峰值，所以我们考虑对叠加了电商波动相对指数的回归均值在6月18日前后加上一个强权，使其时间序列在6月18日前后的需求量数值有一个显著提升，从而提醒决策者对于这种情况进行充足的准备，在库存决策等方面为市场促销浪进行完善的考量和充分的处理。

#### 叠加电商波动相对指数的均值回归

在获得电商波动指数和综合现实情况调查之后，我们建立了叠加电商波动相对指数的均值回归模型，并使用该模型对2023-06-01至2023-06-20时间段进行了回归预测。

以28_808_41为例，其回归结果如图：

![28_808_41](https://gitee.com/guyue12346/cloud-image-library/raw/master/28_808_41.png)

可以看出，回归随机森林在验证集上过滤了波动趋势，而在最终的预测阶段，由于叠加了电商波动相对指数，其波动趋势在均值回归的基础上较大程度得反映出了波动趋势，并且在618附近给出了一个较大的峰值。在面对大型促销这种短暂的规律性波动规律，我们认为包含波动趋势的均值回归在决策过程中更有利于决策者为市场浪潮做出充分的准备，以一种更高的需求量预期进行决策，可以更好的应对突发情况和爆发性需求。因此我们使用叠加电商波动相对指数的均值回归模型对附件6其余时间序列维度进行回归，并将结果保存于结果附件表中。

### 模型评价

##### 模型的优点

1.充分地处理了大量复杂数据，对于每一个维度的时间序列都进行了充分的回归分析。

2.基于DTW的改进K均值聚类分析有效的处理了时间序列这种特殊的数据集的聚类问题。

3.考虑到了回归均值和波动规律两方面，为后续决策提供了多方面可供参考的数值。

4.面对不同场景采用了不同的建模侧重点，以应对复杂的市场变化。

5.创新点较多，引入了如DTW、太阳黑子等研究方法来进行数学建模。

##### 模型的缺点

1.对于数据的峰值部分的考虑不够充分，部分需要考虑的因素有所缺失。

2.处理较为复杂的波动时间序列的回归效果无法达到预期，在波动频繁的地方会产生较大偏差。

3.对于异常情况并没有建立起完善的应对机制，处理异常只能局限于部分场景。

##### 模型的改进

1.对于历史趋势随机变量模型的建模加以完善，使其充分捕捉波动峰值。

2.引入优化算法如遗传算法等对模型的迭代和重构过程加以系统优化，使模型在数值表现上更加良好。

3.建立更加完善了异常应对机制，以处理市场变化中的各种异常情况。

### 参考文献

[1]智能供应链:预测算法理论与实战[M]，北京：电子工业出版社，2023.

[2]《Least Squares Quantization in PCM》，Stuart Lloyd，1957.

[3]《Random Forests》，Leo Breiman，2001

[4]《Dynamic Programming Algorithm Optimization for Spoken Word Recognition》，Sakoe and Chiba ，1978.
